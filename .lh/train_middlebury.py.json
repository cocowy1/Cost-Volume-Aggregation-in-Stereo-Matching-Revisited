{
    "sourceFile": "train_middlebury.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1735525969597,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1735525969597,
            "name": "Commit-0",
            "content": "from __future__ import print_function\nimport sys\nsys.path.append(\"dataloader\")\nfrom torch.autograd import Variable\nfrom models.gwcnet_dca_g import *\nimport argparse\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom util import *\nimport time\nimport dataloader.datasets as DA\nimport dataloader.KITTILoader as lt\nimport matplotlib.pyplot as plt\nimport os\nfrom models.loss import model_loss, focal_loss\nimport torch.backends.cudnn as cudnn\n\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nparser = argparse.ArgumentParser(description='GwcNet')\nparser.add_argument('--maxdisp', type=int, default=240,\n                    help='maxium disparity')\n\nparser.add_argument('--datapath_middlebury', default='/home/wy/文档/Data/Middlebury_half/trainingH',\n                    help='datapath for sceneflow monkaa dataset')\nparser.add_argument('--datapath_middlebury_additional', default='/home/wy/文档/Data/Middlebury_half/additionF',\n                    help='datapath for sceneflow monkaa dataset')\nparser.add_argument('--datapath_middlebury_test', default='/home/wy/文档/Data/Middlebury_half/testH',\n                    help='datapath for sceneflow monkaa dataset')\nparser.add_argument('--datapath_kitti', default='/data/wy/Data/KITTI/kitti/training/',\n                     help='datapath for sceneflow monkaa dataset')\nparser.add_argument('--datapath_kitti_test', default='/data/wy/Data/KITTI/kitti/testing/',\n                    help='datapath for sceneflow monkaa dataset')\n\nparser.add_argument('--epochs', type=int, default=900,\n                    help='number of epochs to train')\nparser.add_argument('--loadmodel', default='./fined/middlebury/checkpoint_559.tar',\n                    help='load model')\nparser.add_argument('--gpus', type=int, nargs='+', default=[0])\nparser.add_argument('--savemodel', default='/home/wy/GwcNet-augment/fined/middlebury',\n                    help='save model')\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='enables CUDA training')\nparser.add_argument('--seed', type=int, default=1, metavar='S',\n                    help='random seed (default: 1)')\nparser.add_argument('--print_freq', type=int, default=800, help='the frequency of printing losses (iterations)')\nparser.add_argument('--lrepochs', type=str, default=\"200:2\", help='the epochs to decay lr: the downscale rate')\nparser.add_argument('--lr', type=float, default=1e-3, help='initial learning rate')\nparser.add_argument('--focal_coefficient', type=float, default=5.0,  help='initial learning rate')\nparser.add_argument('--sparse', type=bool, default=False, help='initial learning rate')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nall_left_img_0, all_right_img_0, all_left_disp_0 = DA.dataloader_middlebury('%s'%args.datapath_middlebury)\nall_left_img_1, all_right_img_1, all_left_disp_1 = DA.dataloader_middleburyadditional('%s'%args.datapath_middlebury_additional)\n\nall_left_img = all_left_img_0 + all_left_img_2\nall_right_img = all_right_img_0 + all_right_img_2\nall_left_disp = all_left_disp_0 + all_left_disp_2\n\nmiddleburyloadertrain = DA.myImageFloder_middlebury(all_left_img, all_right_img, all_left_disp, True)\nmiddleburyloaderaddtional = DA.myImageFloder_middlebury_additional(all_left_img_1, all_right_img_1, all_left_disp_1, True)\nmiddleburyloadertest = DA.myImageFloder_middlebury(all_left_img_0, all_right_img_0, all_left_disp_0, False)\n\nmiddleburyloadertotal = middleburyloaderaddtional + middleburyloadertrain\n\nTrainImgLoader = torch.utils.data.DataLoader(\n    middleburyloadertotal, batch_size=1, shuffle=True, num_workers=4, drop_last=False)\n\nTestImgLoader = torch.utils.data.DataLoader(\n    middleburyloaderaddtional, batch_size=1, shuffle=False, num_workers=4, drop_last=False)\n\nmodel = GwcNet(args.maxdisp)\nif args.cuda:\n    model = nn.DataParallel(model)\n    model.cuda()\n\nif args.loadmodel is not None:\n    print('Load pretrained model')\n    pretrain_dict = torch.load(args.loadmodel)\n    model.load_state_dict(pretrain_dict['state_dict'], strict=True)\n\nprint('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n\noptimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n\ndef train(imgL, imgR, disp_true):\n    model.train()\n    imgL, imgR, disp_true = imgL.cuda(), imgR.cuda(), disp_true.cuda()\n    # ---------\n    mask = ((disp_true < 240) & (disp_true > 0)).byte().bool()\n    mask.detach_()\n    # ----\n    optimizer.zero_grad()\n    cls_outputs, disp_outputs = model(imgL, imgR)\n    # loss = model_loss(outputs, disp_true, mask)\n    loss = focal_loss(cls_outputs, disp_true, args.maxdisp, args.focal_coefficient, args.sparse) + \\\n            model_loss(disp_outputs, disp_true, mask)\n\n    epe = torch.mean(torch.abs(disp_outputs[-1][mask] - disp_true[mask]))\n\n    loss.backward()\n    optimizer.step()\n\n    return loss.item(), epe.item()\n\ndef mytest(imgL, imgR, disp_true):\n    model.eval()\n    imgL = Variable(torch.FloatTensor(imgL))\n    imgR = Variable(torch.FloatTensor(imgR))\n    if args.cuda:\n        imgL, imgR = imgL.cuda(), imgR.cuda()\n\n    mask = (disp_true > 0) & (disp_true < args.maxdisp)\n\n    with torch.no_grad():\n        output3 = model(imgL, imgR)\n\n    pred_disp = output3.squeeze().data.cpu()\n\n    if len(disp_true[mask]) == 0:\n        loss = 0\n        epe = 0\n    else:\n        loss = F.smooth_l1_loss(pred_disp[mask], disp_true[mask], size_average=True)\n        # epe = torch.mean(torch.abs(pred_disp[mask]-disp_true[mask]))  # end-point-error\n        epe = F.l1_loss(pred_disp[mask], disp_true[mask], size_average=True)\n    return loss, epe\n\nprint(\"Traindataset is %d\"%len(TrainImgLoader))\nprint(\"Testdataset is %d\"%len(TestImgLoader))\n\ndef main():\n    for epoch in range(500, args.epochs):\n        print('This is %d-th epoch' % (epoch))\n        total_train_loss = 0.0\n        total_train_epe = 0.0\n        learning_rate_adjust(optimizer, epoch)\n\n        ## training ##\n        # for batch_idx, (imgL_crop, imgR_crop, disp_crop_L) in enumerate(TrainImgLoader):\n        #\n        #     loss, epe = train(imgL_crop, imgR_crop, disp_crop_L)\n        #     total_train_loss += loss\n        #     total_train_epe += epe\n        #\n        #     # if batch_idx % args.print_freq == 0:\n        #     #    print('### batch_idx %5d of total %5d, loss---%.3f, EPE---%.3f ###' %\n        #     #          (batch_idx + 1,\n        #     #           len(TrainImgLoader),\n        #     #           float(total_train_loss / (batch_idx + 1)),\n        #     #           float(total_train_epe / (batch_idx + 1))))\n        #\n        # if (epoch + 1) % 1 == 0:\n        #     avg_epe = total_train_epe / len(TrainImgLoader)\n        #     avg_loss = total_train_loss / len(TrainImgLoader)\n        #     print('Train Epoch----%5d of %d, train_loss---%.3f, train_EPE---%.3f' %\n        #           (epoch + 1, len(TrainImgLoader), avg_loss, avg_epe))\n        #\n        # ## SAVE\n        # savefilename = args.savemodel + '/checkpoint_' + str(epoch) + '.tar'\n        # if epoch > 349 & epoch % 10 == 9:\n        #     torch.save({\n        #     'epoch': epoch,\n        #     'state_dict': model.state_dict(),\n        #     'train_loss': total_train_loss / len(TrainImgLoader),\n        # }, savefilename)\n\n        # ------------- TEST ------------------------------------------------------------\n        if epoch > 399:\n            total_test_loss = 0.0\n            total_test_epe = 0.0\n            start_time = time.time()\n            for batch_idx, (imgL, imgR, disp_L) in enumerate(TestImgLoader):\n                test_loss, test_epe = mytest(imgL, imgR, disp_L)\n                total_test_loss += test_loss\n                total_test_epe += test_epe\n\n            # print(\"this epoch total time is %.3f\"%(time.time()-start_time))\n            if (epoch + 1) % 1 == 0:\n                avg_epe = total_test_epe / len(TestImgLoader)\n                avg_loss = total_test_loss / len(TestImgLoader)\n                print('Test epoch----%5d pf %d, loss---%.3f, EPE---%.3f' %\n                    (epoch + 1, len(TestImgLoader), avg_loss, avg_epe))\n\n\nif __name__ == '__main__':\n    main()\n\n"
        }
    ]
}