{
    "sourceFile": "train_eth3d.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1735525213148,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1735525219638,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -29,9 +29,9 @@\n parser.add_argument('--datapath_kitti2015_test', default='/home/wy/Data/kitti_stereo_2015/testing/',\n                      help='datapath for sceneflow monkaa dataset')\n parser.add_argument('--datapath_kitti', default='/home/wy/Data/kitti_stereo_2012/training/',\n                      help='datapath for sceneflow monkaa dataset')\n-parser.add_argument('--datapath_kitti_test', default='/home/wy/文档/Data/kitti_stereo_2012/testing/',\n+parser.add_argument('--datapath_kitti_test', default='/home/wy//Data/kitti_stereo_2012/testing/',\n                     help='datapath for sceneflow monkaa dataset')\n \n parser.add_argument('--datapath', default='/home/wy/文档/Data',\n                     help='datapath for sceneflow monkaa dataset')\n"
                },
                {
                    "date": 1735525758233,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,9 +1,9 @@\n from __future__ import print_function\n import sys\n sys.path.append(\"dataloader\")\n from torch.autograd import Variable\n-from models.dca_mport *\n+from models.dca_g mport *\n import argparse\n from torch.utils.tensorboard import SummaryWriter\n import torch\n import torch.nn as nn\n"
                }
            ],
            "date": 1735525213148,
            "name": "Commit-0",
            "content": "from __future__ import print_function\nimport sys\nsys.path.append(\"dataloader\")\nfrom torch.autograd import Variable\nfrom models.gwcnet_au_h3 import *\nimport argparse\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom util import *\nimport time\nimport dataloader.datasets as DA\nimport dataloader.KITTILoader as lt\n\nimport os\nfrom models.loss import model_loss\nimport torch.backends.cudnn as cudnn\n\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nparser = argparse.ArgumentParser(description='GwcNet')\nparser.add_argument('--maxdisp', type=int, default=192,\n                    help='maxium disparity')\nparser.add_argument('--datapath_kitti2015', default='/home/wy/Data/kitti_stereo_2015/training/',\n                    help='datapath for sceneflow monkaa dataset')\nparser.add_argument('--datapath_kitti2015_test', default='/home/wy/文档/Data/kitti_stereo_2015/testing/',\n                     help='datapath for sceneflow monkaa dataset')\nparser.add_argument('--datapath_kitti', default='/home/wy/文档/Data/kitti_stereo_2012/training/',\n                     help='datapath for sceneflow monkaa dataset')\nparser.add_argument('--datapath_kitti_test', default='/home/wy/文档/Data/kitti_stereo_2012/testing/',\n                    help='datapath for sceneflow monkaa dataset')\n\nparser.add_argument('--datapath', default='/home/wy/文档/Data',\n                    help='datapath for sceneflow monkaa dataset')\n\nparser.add_argument('--epochs', type=int, default=800,\n                    help='number of epochs to train')\nparser.add_argument('--loadmodel', default='./fined/h3/kitti15/checkpoint_699.tar',\n                    help='load model')\nparser.add_argument('--gpus', type=int, nargs='+', default=[0])\nparser.add_argument('--savemodel', default='/home/wy/GwcNet-augment/fined/KITTI15',\n                    help='save model')\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='enables CUDA training')\nparser.add_argument('--seed', type=int, default=1, metavar='S',\n                    help='random seed (default: 1)')\nparser.add_argument('--print_freq', type=int, default=1, help='the frequency of printing losses (iterations)')\nparser.add_argument('--lrepochs', type=str, default=\"200:2\", help='the epochs to decay lr: the downscale rate')\nparser.add_argument('--lr', type=float, default=1e-3, help='initial learning rate')\nparser.add_argument('--focal_coefficient', type=float, default=5.0,  help='initial learning rate')\nparser.add_argument('--sparse', type=bool, default=False, help='initial learning rate')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nall_left_img, all_right_img, all_left_disp = DA.dataloader('%s/eth3d'%args.datapath)\neth3dloadertrain = DA.myImageFloder_eth3d(all_left_img, all_right_img, all_left_disp, True)\ntest_left_img, test_right_img, test_left_disp = DA.dataloader('%s/eth3d'%args.datapath)\neth3dloadertest = DA.myImageFloder_eth3d(all_left_img, all_right_img, all_left_disp, False)\n\nTrainImgLoader = torch.utils.data.DataLoader(\n    DA.myImageFloder_eth3d(all_left_img, all_right_img, all_left_disp, True),\n    batch_size=1, shuffle=True, num_workers=4, drop_last=False)\n\nTestImgLoader = torch.utils.data.DataLoader(\n    DA.myImageFloder_eth3d(all_left_img, all_right_img, all_left_disp, False),\n    batch_size=1, shuffle=False, num_workers=4, drop_last=False)\n\nmodel = GwcNet_GC(args.maxdisp)\nif args.cuda:\n    model = nn.DataParallel(model)\n    model.cuda()\n\nif args.loadmodel is not None:\n    print('Load pretrained model')\n    pretrain_dict = torch.load(args.loadmodel)\n    model.load_state_dict(pretrain_dict['state_dict'])\n\nprint('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n\noptimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n\ndef train(imgL, imgR, disp_true):\n    model.train()\n    imgL, imgR, disp_true = imgL.cuda(), imgR.cuda(), disp_true.cuda()\n    # ---------\n    mask = ((disp_true < 192) & (disp_true > 0)).byte().bool()\n    mask.detach_()\n    # ----\n    optimizer.zero_grad()\n    disp_ests = model(imgL, imgR)\n\n    loss = model_loss(disp_ests, disp_true, mask)\n    epe = torch.mean(torch.abs(disp_ests[-1][mask] - disp_true[mask]))\n\n    loss.backward()\n    optimizer.step()\n\n    return loss.item(), epe.item()\n\ndef mytest(imgL, imgR, disp_true):\n    model.eval()\n    imgL = Variable(torch.FloatTensor(imgL))\n    imgR = Variable(torch.FloatTensor(imgR))\n    if args.cuda:\n        imgL, imgR = imgL.cuda(), imgR.cuda()\n\n    mask = (disp_true > 0) & (disp_true < args.maxdisp)\n\n    if imgL.shape[2] % 16 != 0:\n        times = imgL.shape[2] // 16\n        top_pad = (times + 1) * 16 - imgL.shape[2]\n    else:\n        top_pad = 0\n\n    if imgL.shape[3] % 16 != 0:\n        times = imgL.shape[3] // 16\n        right_pad = (times + 1) * 16 - imgL.shape[3]\n    else:\n        right_pad = 0\n\n    imgL = F.pad(imgL, (0, right_pad, top_pad, 0))\n    imgR = F.pad(imgR, (0, right_pad, top_pad, 0))\n\n    with torch.no_grad():\n        output3, _ = model(imgL, imgR)\n    if top_pad != 0:\n        pred_disp = output3[:, top_pad:, :]\n    else:\n        pred_disp = output3\n    pred_disp = pred_disp.data.cpu()\n\n    if len(disp_true[mask]) == 0:\n        loss = 0\n        epe = 0\n    else:\n        loss = F.smooth_l1_loss(pred_disp[mask], disp_true[mask], size_average=True)\n        # epe = torch.mean(torch.abs(pred_disp[mask]-disp_true[mask]))  # end-point-error\n        epe = F.l1_loss(pred_disp[mask], disp_true[mask], size_average=True)\n    return loss, epe\n\nprint(\"Traindataset is %d\"%len(TrainImgLoader))\nprint(\"Testdataset is %d\"%len(TestImgLoader))\n\ndef main():\n    for epoch in range(1, args.epochs):\n        print('This is %d-th epoch' % (epoch))\n        total_train_loss = 0.0\n        total_train_epe = 0.0\n        learning_rate_adjust(optimizer, epoch)\n\n        # ## training ##\n        # for batch_idx, (imgL_crop, imgR_crop, disp_crop_L) in enumerate(TrainImgLoader):\n        #\n        #     loss, epe = train(imgL_crop, imgR_crop, disp_crop_L)\n        #     total_train_loss += loss\n        #     total_train_epe += epe\n        #\n        #     if batch_idx % args.print_freq == 0:\n        #        print('### batch_idx %5d of total %5d, loss---%.3f, EPE---%.3f ###' %\n        #              (batch_idx + 1,\n        #               len(TrainImgLoader),\n        #               float(total_train_loss / (batch_idx + 1)),\n        #               float(total_train_epe / (batch_idx + 1))))\n        #\n        # if (epoch + 1) % 1 == 0:\n        #     avg_epe = total_train_epe / len(TrainImgLoader)\n        #     avg_loss = total_train_loss / len(TrainImgLoader)\n        #     print('Train Epoch----%5d of %d, train_loss---%.3f, train_EPE---%.3f' %\n        #           (epoch + 1, len(TrainImgLoader), avg_loss, avg_epe))\n        #\n        # ## SAVE\n        # savefilename = args.savemodel + '/checkpoint_' + str(epoch) + '.tar'\n        # if epoch > 449:\n        #     torch.save({\n        #     'epoch': epoch,\n        #     'state_dict': model.state_dict(),\n        #     'train_loss': total_train_loss / len(TrainImgLoader),\n        # }, savefilename)\n\n        # ------------- TEST ------------------------------------------------------------\n        if epoch > -1:\n            total_test_loss = 0.0\n            total_test_epe = 0.0\n            start_time = time.time()\n            for batch_idx, (imgL, imgR, disp_L) in enumerate(TestImgLoader):\n                test_loss, test_epe = mytest(imgL, imgR, disp_L)\n                total_test_loss += test_loss\n                total_test_epe += test_epe\n\n            # print(\"this epoch total time is %.3f\"%(time.time()-start_time))\n            if (epoch + 1) % 1 == 0:\n                avg_epe = total_test_epe / len(TestImgLoader)\n                avg_loss = total_test_loss / len(TestImgLoader)\n                print('Test epoch--%5d pf %d, loss-%.3f, EPE-%.3f' %\n                    (epoch + 1, len(TestImgLoader), avg_loss, avg_epe))\n\n\nif __name__ == '__main__':\n    main()\n\n"
        }
    ]
}