{
    "sourceFile": "main_dca.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1735525325302,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1735525338649,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -245,9 +245,9 @@\n \n     return loss, metrics, mpa, mIoU\n \n def main():\n-    start_epoch = 17\n+    start_epoch = 0\n     for epoch in range(start_epoch, args.epochs):\n         print('This is %d-th epoch, focal_loss=5' % (epoch + 1))\n         total_train_loss = 0.0\n         total_train_epe = 0.0\n"
                },
                {
                    "date": 1735525613430,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,9 +6,9 @@\n import torch.nn.parallel\n import torch.backends.cudnn as cudnn\n import torch.optim as optim\n import torch.utils.data\n-from models.gwcnet_dca4_g import *\n+from models.gwcnet_dca_g import *\n from utils import *\n \n import dataloader.datasets as DA\n from models.loss import focal_loss, model_loss\n"
                },
                {
                    "date": 1735525620096,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,9 +18,9 @@\n np.seterr(divide='ignore', invalid='ignore')\n \n parser = argparse.ArgumentParser(description='Group-wise Correlation Stereo Network (GwcNet)')\n parser.add_argument('--maxdisp', type=int, default=192, help='maximum disparity')\n-parser.add_argument('--datapath', default='/home/wy/文档/Data/SceneFlow/', help='datapath')\n+parser.add_argument('--datapath', default='/home/wy/Data/SceneFlow/', help='datapath')\n \n parser.add_argument('--print_freq', type=int, default=200, help='the freuency of printing losses (iterations)')\n parser.add_argument('--lrepochs', type=str, default=\"12,20,24,28:2\", help='the epochs to decay lr: the downscale rate')\n parser.add_argument('--lr', type=float, default=1e-3, help='initial learning rate')\n"
                },
                {
                    "date": 1735525630114,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,10 +27,10 @@\n parser.add_argument('--cuda', action='store_true', default=True, help='enables CUDA training')\n parser.add_argument('--seed', type=int, default=1, metavar='S', help='random seed (default: 1)')\n \n parser.add_argument('--epochs', type=int, default=40, help='number of epochs to train')\n-parser.add_argument('--savemodel', default='./trained/focal_loss/5', help='save model')\n-parser.add_argument('--loadmodel', default='./trained/4/checkpoint_48.tar', help='load model')\n+parser.add_argument('--savemodel', default='./trained/', help='save model')\n+parser.add_argument('--loadmodel', default='./trained/4/checkpoint_final.tar', help='load model')\n parser.add_argument('--focal_coefficient', type=float, default=5.0, help='initial learning rate')\n parser.add_argument('--sparse', type=bool, default=False, help='initial learning rate')\n \n # parse arguments, set seeds\n"
                }
            ],
            "date": 1735525325302,
            "name": "Commit-0",
            "content": "from __future__ import print_function, division\nimport argparse\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nfrom models.gwcnet_dca4_g import *\nfrom utils import *\n\nimport dataloader.datasets as DA\nfrom models.loss import focal_loss, model_loss\ncudnn.benchmark = True\n\nimport numpy as np\nnp.seterr(divide='ignore', invalid='ignore')\n\nparser = argparse.ArgumentParser(description='Group-wise Correlation Stereo Network (GwcNet)')\nparser.add_argument('--maxdisp', type=int, default=192, help='maximum disparity')\nparser.add_argument('--datapath', default='/home/wy/文档/Data/SceneFlow/', help='datapath')\n\nparser.add_argument('--print_freq', type=int, default=200, help='the freuency of printing losses (iterations)')\nparser.add_argument('--lrepochs', type=str, default=\"12,20,24,28:2\", help='the epochs to decay lr: the downscale rate')\nparser.add_argument('--lr', type=float, default=1e-3, help='initial learning rate')\nparser.add_argument('--cuda', action='store_true', default=True, help='enables CUDA training')\nparser.add_argument('--seed', type=int, default=1, metavar='S', help='random seed (default: 1)')\n\nparser.add_argument('--epochs', type=int, default=40, help='number of epochs to train')\nparser.add_argument('--savemodel', default='./trained/focal_loss/5', help='save model')\nparser.add_argument('--loadmodel', default='./trained/4/checkpoint_48.tar', help='load model')\nparser.add_argument('--focal_coefficient', type=float, default=5.0, help='initial learning rate')\nparser.add_argument('--sparse', type=bool, default=False, help='initial learning rate')\n\n# parse arguments, set seeds\nargs = parser.parse_args()\n# dataset, dataloader\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nall_left_img, all_right_img, all_left_disp, test_left_img, test_right_img, test_left_disp = DA.dataloader_SceneFlow(args.datapath)\n\nTrainImgLoader = torch.utils.data.DataLoader(\n    DA.myImageFloder_SceneFlow(all_left_img, all_right_img, all_left_disp, True),\n    batch_size=1, shuffle=True, num_workers=8, drop_last=False)\n\nTestImgLoader = torch.utils.data.DataLoader(\n    DA.myImageFloder_SceneFlow(test_left_img, test_right_img, test_left_disp, False),\n    batch_size=1, shuffle=False, num_workers=8, drop_last=False)\n\n# model, optimizer\nmodel = GwcNet(args.maxdisp)\nmodel = nn.DataParallel(model, device_ids=[0])\nmodel.cuda()\n\n# load parameters\nif args.loadmodel is not None:\n    print('Load pretrained model')\n    pretrain_dict = torch.load(args.loadmodel)\n    model.load_state_dict(pretrain_dict['state_dict'], strict=True)\n\nprint('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\noptimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n\nclass SegmentationMetric(object):\n    def __init__(self, numClass):\n        self.numClass = numClass\n        self.confusionMatrix = np.zeros((self.numClass,) * 2)\n\n    def pixelAccuracy(self):\n        # return all class overall pixel accuracy\n        #  PA = acc = (TP + TN) / (TP + TN + FP + TN)\n        acc = np.diag(self.confusionMatrix).sum() / self.confusionMatrix.sum()\n        return acc\n\n    def classPixelAccuracy(self):\n        # return each category pixel accuracy(A more accurate way to call it precision)\n        # acc = (TP) / TP + FP\n        classAcc = np.diag(self.confusionMatrix) / self.confusionMatrix.sum(axis=1)\n        return classAcc  # 返回的是一个列表值，如：[0.90, 0.80, 0.96]，表示类别1 2 3各类别的预测准确率\n\n    def meanPixelAccuracy(self):\n        classAcc = self.classPixelAccuracy()\n        meanAcc = np.nanmean(classAcc)  # np.nanmean 求平均值，nan表示遇到Nan类型，其值取为0\n        return meanAcc  # 返回单个值，如：np.nanmean([0.90, 0.80, 0.96, nan, nan]) = (0.90 + 0.80 + 0.96） / 3 =  0.89\n\n    def meanIntersectionOverUnion(self):\n        # Intersection = TP Union = TP + FP + FN\n        # IoU = TP / (TP + FP + FN)\n        intersection = np.diag(self.confusionMatrix)  # 取对角元素的值，返回列表\n        union = np.sum(self.confusionMatrix, axis=1) + np.sum(self.confusionMatrix, axis=0) - np.diag(\n            self.confusionMatrix)  # axis = 1表示混淆矩阵行的值，返回列表； axis = 0表示取混淆矩阵列的值，返回列表\n        IoU = intersection / union  # 返回列表，其值为各个类别的IoU\n        mIoU = np.nanmean(IoU)  # 求各类别IoU的平均\n        return mIoU\n\n    def genConfusionMatrix(self, imgPredict, imgLabel):  # 同FCN中score.py的fast_hist()函数\n        # remove classes from unlabeled pixels in gt image and predict\n        mask = (imgLabel >= 0) & (imgLabel < self.numClass)\n        label = self.numClass * imgLabel[mask] + imgPredict[mask]\n        count = np.bincount(label, minlength=self.numClass ** 2)\n        confusionMatrix = count.reshape(self.numClass, self.numClass)\n        return confusionMatrix\n\n    def Frequency_Weighted_Intersection_over_Union(self):\n        # FWIOU =     [(TP+FN)/(TP+FP+TN+FN)] *[TP / (TP + FP + FN)]\n        freq = np.sum(self.confusion_matrix, axis=1) / np.sum(self.confusion_matrix)\n        iu = np.diag(self.confusion_matrix) / (\n                np.sum(self.confusion_matrix, axis=1) + np.sum(self.confusion_matrix, axis=0) -\n                np.diag(self.confusion_matrix))\n        FWIoU = (freq[freq > 0] * iu[freq > 0]).sum()\n        return FWIoU\n\n    def addBatch(self, imgPredict, imgLabel):\n        assert imgPredict.shape == imgLabel.shape\n        self.confusionMatrix += self.genConfusionMatrix(imgPredict, imgLabel)\n\n    def reset(self):\n        self.confusionMatrix = np.zeros((self.numClass, self.numClass))\n\ndef train(imgL, imgR, disp_true):\n    model.train()\n    imgL, imgR, disp_true = imgL.cuda(), imgR.cuda(), disp_true.cuda()\n    # ---------\n    disp_true = disp_true\n    mask = ((disp_true < 192) & (disp_true > 0)).byte().bool()\n    mask.detach_()\n    # ----\n    optimizer.zero_grad()\n    cls_outputs, disp_outputs = model(imgL, imgR)\n    loss = focal_loss(cls_outputs, disp_true, args.maxdisp, args.focal_coefficient, args.sparse) + \\\n            model_loss(disp_outputs, disp_true, mask)\n\n    # disp_outputs = model(imgL, imgR)\n    # loss = model_loss(disp_outputs, disp_true, mask)\n    epe = torch.mean(torch.abs(disp_outputs[-1][mask] - disp_true[mask]))\n\n    loss.backward()\n    optimizer.step()\n    return loss.item(), epe.item()\n\ndef mytest(imgL, imgR, disp_true):\n    model.eval()\n    imgL = Variable(torch.FloatTensor(imgL))\n    imgR = Variable(torch.FloatTensor(imgR))\n\n    if args.cuda:\n        imgL, imgR, disp_true = imgL.cuda(), imgR.cuda(), disp_true.cuda()\n\n    mask = (disp_true > 0) & (disp_true < args.maxdisp)\n\n    if imgL.shape[2] % 16 != 0:\n        times = imgL.shape[2] // 16\n        top_pad = (times + 1) * 16 - imgL.shape[2]\n    else:\n        top_pad = 0\n\n    if imgL.shape[3] % 16 != 0:\n        times = imgL.shape[3] // 16\n        right_pad = (times + 1) * 16 - imgL.shape[3]\n    else:\n        right_pad = 0\n\n    imgL = F.pad(imgL, (0, right_pad, top_pad, 0))\n    imgR = F.pad(imgR, (0, right_pad, top_pad, 0))\n\n    with torch.no_grad():\n        output3, pred_au = model(imgL, imgR)\n\n    if top_pad != 0:\n        pred_disp = output3.squeeze(1)[:, top_pad:, :]\n    else:\n        pred_disp = output3\n    # pred_disp = pred_disp.data.cpu()\n\n    if len(disp_true[mask]) == 0:\n        loss = 0\n        metrics = {\n            'epe': 0,\n            '1px': 0,\n            '3px': 0,\n        }\n        mpa = {\n            'mpa0': 0,\n            'mpa1': 0,\n            'mpa2': 0,\n        }\n\n        mIoU = {\n            'mIoU0': 0,\n            'mIoU1': 0,\n            'mIoU2': 0,\n        }\n        print('it meet a 0 number')\n    else:\n        loss = F.smooth_l1_loss(pred_disp[mask], disp_true[mask], size_average=True)\n        # epe = torch.mean(torch.abs(pred_disp[mask]-disp_true[mask]))  # end-point-error\n        # epe = F.l1_loss(pred_disp[mask], disp_true[mask], size_average=True)\n        epe = (pred_disp - disp_true).abs()\n        epe = epe.view(-1)[mask.view(-1)]\n\n        metrics = {\n            'epe': epe.mean().item(),\n            '1px': (epe > 1).float().mean().item(),\n            '3px': (epe > 3).float().mean().item(),\n        }\n\n        disp_gt = disp_true.clone()\n        disp_gt = F.adaptive_avg_pool2d(disp_gt / 8, (540//8, 960//8)).floor().cpu().numpy().astype('int64')\n        pred_au_0 = pred_au[0].argmax(1)[:, 1:, ...].cpu().numpy()\n        pred_au_1 = pred_au[1].argmax(1)[:, 1:, ...].cpu().numpy()\n        pred_au_2 = pred_au[2].argmax(1)[:, 1:, ...].cpu().numpy()\n\n        metric = SegmentationMetric(24)  # 3表示有3个分类，有几个分类就填几\n        metric.addBatch(pred_au_0, disp_gt)\n        pa0 = metric.pixelAccuracy()\n        cpa0 = metric.classPixelAccuracy()\n        mpa0 = metric.meanPixelAccuracy()\n        mIoU0 = metric.meanIntersectionOverUnion()\n\n        metric.addBatch(pred_au_1, disp_gt)\n        pa1 = metric.pixelAccuracy()\n        cpa1 = metric.classPixelAccuracy()\n        mpa1 = metric.meanPixelAccuracy()\n        mIoU1 = metric.meanIntersectionOverUnion()\n\n        metric.addBatch(pred_au_2, disp_gt)\n        pa2 = metric.pixelAccuracy()\n        cpa2 = metric.classPixelAccuracy()\n        mpa2 = metric.meanPixelAccuracy()\n        mIoU2 = metric.meanIntersectionOverUnion()\n\n        mpa = {\n            'mpa0': mpa0,\n            'mpa1': mpa1,\n            'mpa2': mpa2,\n        }\n\n        mIoU = {\n            'mIoU0': mIoU0,\n            'mIoU1': mIoU1,\n            'mIoU2': mIoU2,\n        }\n\n    return loss, metrics, mpa, mIoU\n\ndef main():\n    start_epoch = 17\n    for epoch in range(start_epoch, args.epochs):\n        print('This is %d-th epoch, focal_loss=5' % (epoch + 1))\n        total_train_loss = 0.0\n        total_train_epe = 0.0\n        adjust_learning_rate(optimizer, epoch, args.lr, args.lrepochs)\n\n        # # ## training ##\n        for batch_idx, (imgL_crop, imgR_crop, disp_crop_L) in enumerate(TrainImgLoader):\n        \n            loss, epe = train(imgL_crop, imgR_crop, disp_crop_L)\n            total_train_loss += loss\n            total_train_epe += epe\n        \n            if batch_idx % args.print_freq == 0:\n                print('### batch_idx %4d of total %4d, loss---%.3f, EPE---%.3f ###' %\n                      (batch_idx + 1,\n                       len(TrainImgLoader),\n                       float(total_train_loss / (batch_idx + 1)),\n                       float(total_train_epe / (batch_idx + 1))))\n        \n        print('epoch %d total train loss = %.3f, total train epe = %.3f' % (epoch + 1,\n                                                                            total_train_loss / len(TrainImgLoader),\n                                                                            total_train_epe / len(TrainImgLoader)))\n        \n        # SAVE\n        if (epoch + 1) > 18:\n            savefilename = args.savemodel + '/checkpoint_' + str(epoch) + '.tar'\n            torch.save({\n                'epoch': epoch,\n                'state_dict': model.state_dict(),\n                'train_loss': total_train_loss / len(TrainImgLoader),\n            }, savefilename)\n\n        # ------------- TEST ------------------------------------------------------------\n        if (epoch + 1) > -1:\n            total_test_loss = 0.0\n            total_test_epe = 0.0\n            total_test_1px = 0.0\n            total_test_3px = 0.0\n\n            total_test_mpa0 = 0.0\n            total_text_miou0 = 0.0\n            total_test_mpa1 = 0.0\n            total_text_miou1 = 0.0\n            total_test_mpa2 = 0.0\n            total_text_miou2 = 0.0\n\n\n            for batch_idx, (imgL, imgR, disp_L) in enumerate(TestImgLoader):\n                test_loss, metrics, mpa, miou = mytest(imgL, imgR, disp_L)\n                total_test_loss += test_loss\n                total_test_epe += metrics['epe']\n                total_test_1px += metrics['1px']\n                total_test_3px += metrics['3px']\n                total_test_mpa0 += mpa['mpa0']\n                total_text_miou0 += miou['mIoU0']\n                total_test_mpa1 += mpa['mpa1']\n                total_text_miou1 += miou['mIoU1']\n                total_test_mpa2 += mpa['mpa2']\n                total_text_miou2 += miou['mIoU2']\n\n                if batch_idx % args.print_freq == 0:\n                    print(\n                        '### batch_idx %5d of total %5d, test loss=%.3f, test_epe=%.3f, test_1px=%.3f, test_3px=%.3f,'\n                        'test_mpa0=%.3f, test_miou0=%.3f, test_mpa1=%.3f, test_miou1=%.3f, '\n                        'test_mpa2=%.3f, test_miou2=%.3f' % (\n                            batch_idx + 1,\n                             len(TestImgLoader),\n                            total_test_loss / (batch_idx + 1), total_test_epe / (batch_idx + 1),\n                            (total_test_1px * 100) / (batch_idx + 1), (total_test_3px * 100) / (batch_idx + 1),\n                            (total_test_mpa0 * 100) / (batch_idx + 1), (total_text_miou0 * 100) / (batch_idx + 1),\n                            (total_test_mpa1 * 100) / (batch_idx + 1), (total_text_miou1 * 100) / (batch_idx + 1),\n                            (total_test_mpa2 * 100) / (batch_idx + 1), (total_text_miou2 * 100) / (batch_idx + 1),\n                        ))\n\n            print(\n                'epoch %d, total test loss=%.3f, total_test_epe=%.3f, total_test_1px=%.3f, total_test_3px=%.3f,'\n                ' total_test_mpa0=%.3f, total_test_miou0=%.3f, total_test_mpa1=%.3f, total_test_miou1=%.3f, '\n                'total_test_mpa2=%.3f, total_test_miou2=%.3f' % (\n                    epoch + 1,\n                    total_test_loss / len(TestImgLoader), total_test_epe / len(TestImgLoader),\n                    (total_test_1px * 100) / len(TestImgLoader), (total_test_3px * 100) / len(TestImgLoader),\n                    (total_test_mpa0 * 100) / len(TestImgLoader), (total_text_miou0 * 100) / len(TestImgLoader),\n                    (total_test_mpa1 * 100) / len(TestImgLoader), (total_text_miou1 * 100) / len(TestImgLoader),\n                    (total_test_mpa2 * 100) / len(TestImgLoader), (total_text_miou2 * 100) / len(TestImgLoader)\n                ))\n\nif __name__ == '__main__':\n    main()\n"
        }
    ]
}