{
    "sourceFile": "dataloader/datasets.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1735525261506,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1735525913908,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -161,33 +161,8 @@\n     return left_train, right_train, disp_train_L, left_val, right_val, disp_val_L\n     # return left_train, right_train, disp_train_L\n \n \n-def dataloader_KITTI2015_test(filepath):\n-    left_fold = 'image_2/'\n-    right_fold = 'image_3/'\n-    disp_L = 'disp_occ_0/'\n-    disp_R = 'disp_occ_1/'\n-\n-    image = [img for img in os.listdir(filepath + left_fold) if img.find('_10') > -1]\n-\n-    train = image[:]\n-    val = image[:]\n-\n-    left_train = [filepath + left_fold + img for img in train]\n-    right_train = [filepath + right_fold + img for img in train]\n-    disp_train_L = [filepath + disp_L + img for img in train]\n-    disp_train_R = [filepath + disp_R + img for img in train]\n-\n-    left_val = [filepath + left_fold + img for img in val]\n-    right_val = [filepath + right_fold + img for img in val]\n-    disp_val_L = [filepath + disp_L + img for img in val]\n-    disp_val_R = [filepath + disp_R + img for img in val]\n-\n-    return left_train, right_train, disp_train_L, left_val, right_val, disp_val_L\n-    # return left_train, right_train, disp_train_L\n-\n-\n def dataloader_SceneFlow(filepath):\n     classes = [d for d in os.listdir(filepath) if os.path.isdir(os.path.join(filepath, d))]\n     image = [img for img in classes if img.find('frames_finalpass') > -1]\n     disp = [dsp for dsp in classes if dsp.find('disparity') > -1]\n"
                },
                {
                    "date": 1735525928807,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -57,17 +57,8 @@\n   disp_train_L = ['%s/%s/disp0GT.pfm' % (filepath,img) for img in img_list]\n \n   return left_train, right_train, disp_train_L\n \n-def dataloader_eth3dtest(filepath):\n-  img_list = [i.split('/')[-1] for i in glob.glob('%s/*'%filepath) if os.path.isdir(i)]\n-\n-  left_train  = ['%s/%s/im0.png'% (filepath, img) for img in img_list]\n-  right_train = ['%s/%s/im1.png'% (filepath,img) for img in img_list]\n-  disp_train_L = ['%s/%s/disp0GT.png' % (filepath,img) for img in img_list]\n-\n-  return left_train, right_train, disp_train_L\n-\n def dataloader_middlebury(filepath):\n   img_list = [i.split('/')[-1] for i in glob.glob('%s/*'%filepath) if os.path.isdir(i)]\n \n   left_train  = ['%s/%s/im0.png'% (filepath, img) for img in img_list]\n"
                },
                {
                    "date": 1735525929247,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,18 +75,8 @@\n   disp_train_L = ['%s/%s/disp0.pfm' % (filepath,img) for img in img_list]\n \n   return left_train, right_train, disp_train_L\n \n-def dataloader_middleburytest(filepath):\n-  img_list = [i.split('/')[-1] for i in glob.glob('%s/*'%filepath) if os.path.isdir(i)]\n-\n-  left_train  = ['%s/%s/im0.png'% (filepath, img) for img in img_list]\n-  right_train = ['%s/%s/im1.png'% (filepath,img) for img in img_list]\n-  disp_train_L = ['%s/%s/disp0GT.pfm' % (filepath,img) for img in img_list]\n-\n-  return left_train, right_train, disp_train_L\n-\n-\n def dataloader_KITTI(filepath):\n     left_fold = 'colored_0/'\n     right_fold = 'colored_1/'\n     disp_noc = 'disp_occ/'\n@@ -106,29 +96,8 @@\n \n     return left_train, right_train, disp_train, left_val, right_val, disp_val\n \n \n-def dataloader_KITTI_test(filepath):\n-    left_fold = 'colored_0/'\n-    right_fold = 'colored_1/'\n-    disp_noc = 'disp_occ/'\n-\n-    image = [img for img in os.listdir(filepath + left_fold) if img.find('_10') > -1]\n-\n-    train = image[:]\n-    val = image[:]\n-\n-    left_train = [filepath + left_fold + img for img in train]\n-    right_train = [filepath + right_fold + img for img in train]\n-    disp_train = [filepath + disp_noc + img for img in train]\n-\n-    left_val = [filepath + left_fold + img for img in val]\n-    right_val = [filepath + right_fold + img for img in val]\n-    disp_val = [filepath + disp_noc + img for img in val]\n-\n-    return left_train, right_train, disp_train, left_val, right_val, disp_val\n-\n-\n def dataloader_KITTI2015(filepath):\n     left_fold = 'image_2/'\n     right_fold = 'image_3/'\n     disp_L = 'disp_occ_0/'\n"
                },
                {
                    "date": 1735525989624,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,10 +18,8 @@\n IMG_EXTENSIONS = [\n     '.jpg', '.JPG', '.jpeg', '.JPEG',\n     '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n ]\n-\n-\n def is_image_file(filename):\n     return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n \n def default_loader(path):\n@@ -689,10 +687,8 @@\n     def __len__(self):\n         return len(self.left)\n \n \n-\n-\n class InputPadder:\n     \"\"\" Pads images such that dimensions are divisible by 8 \"\"\"\n     def __init__(self, dims, mode='sintel', divis_by=8):\n         self.ht, self.wd = dims[-2:]\n"
                }
            ],
            "date": 1735525261506,
            "name": "Commit-0",
            "content": "import os\nimport os.path\n\nimport random\n\nimport cv2\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport numpy as np\nfrom dataloader.data_io import get_transform\nfrom dataloader.readpfm import readPFM as pfm_imread\nimport torch.utils.data as data\nimport torch\nimport torchvision\nimport torch.nn.functional as F\nimport glob\n\nIMG_EXTENSIONS = [\n    '.jpg', '.JPG', '.jpeg', '.JPEG',\n    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n]\n\n\ndef is_image_file(filename):\n    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n\ndef default_loader(path):\n    return Image.open(path).convert('RGB')\n\ndef cv2_disparity_loader(path):\n    disp = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n    return disp.astype(np.float32) / 32\n\ndef disparity_loader(path):\n    if '.png' in path:\n        return Image.open(path)\n    else:\n        return pfm_imread(path)\n\n# SceneFlow_disparity\ndef disparity_loader_SceneFlow(path):\n    return pfm_imread(path)\n\n# KITTI_disparity\ndef disparity_loader_eth3d(path):\n    return pfm_imread(path)\n\n# KITTI_disparity\ndef disparity_loader_KITTI(path):\n    return Image.open(path)\n\ndef dataloader_eth3d(filepath):\n  img_list = [i.split('/')[-1] for i in glob.glob('%s/*'%filepath) if os.path.isdir(i)]\n\n  left_train  = ['%s/%s/im0.png'% (filepath, img) for img in img_list]\n  right_train = ['%s/%s/im1.png'% (filepath,img) for img in img_list]\n  disp_train_L = ['%s/%s/disp0GT.pfm' % (filepath,img) for img in img_list]\n\n  return left_train, right_train, disp_train_L\n\ndef dataloader_eth3dtest(filepath):\n  img_list = [i.split('/')[-1] for i in glob.glob('%s/*'%filepath) if os.path.isdir(i)]\n\n  left_train  = ['%s/%s/im0.png'% (filepath, img) for img in img_list]\n  right_train = ['%s/%s/im1.png'% (filepath,img) for img in img_list]\n  disp_train_L = ['%s/%s/disp0GT.png' % (filepath,img) for img in img_list]\n\n  return left_train, right_train, disp_train_L\n\ndef dataloader_middlebury(filepath):\n  img_list = [i.split('/')[-1] for i in glob.glob('%s/*'%filepath) if os.path.isdir(i)]\n\n  left_train  = ['%s/%s/im0.png'% (filepath, img) for img in img_list]\n  right_train = ['%s/%s/im1.png'% (filepath,img) for img in img_list]\n  disp_train_L = ['%s/%s/disp0GT.pfm' % (filepath,img) for img in img_list]\n\n  return left_train, right_train, disp_train_L\n\ndef dataloader_middleburyadditional(filepath):\n  img_list = [i.split('/')[-1] for i in glob.glob('%s/*'%filepath) if os.path.isdir(i)]\n\n  left_train  = ['%s/%s/im0.png'% (filepath, img) for img in img_list]\n  right_train = ['%s/%s/im1.png'% (filepath,img) for img in img_list]\n  disp_train_L = ['%s/%s/disp0.pfm' % (filepath,img) for img in img_list]\n\n  return left_train, right_train, disp_train_L\n\ndef dataloader_middleburytest(filepath):\n  img_list = [i.split('/')[-1] for i in glob.glob('%s/*'%filepath) if os.path.isdir(i)]\n\n  left_train  = ['%s/%s/im0.png'% (filepath, img) for img in img_list]\n  right_train = ['%s/%s/im1.png'% (filepath,img) for img in img_list]\n  disp_train_L = ['%s/%s/disp0GT.pfm' % (filepath,img) for img in img_list]\n\n  return left_train, right_train, disp_train_L\n\n\ndef dataloader_KITTI(filepath):\n    left_fold = 'colored_0/'\n    right_fold = 'colored_1/'\n    disp_noc = 'disp_occ/'\n\n    image = [img for img in os.listdir(filepath + left_fold) if img.find('_10') > -1]\n\n    train = image[:]\n    val = image[:]\n\n    left_train = [filepath + left_fold + img for img in train]\n    right_train = [filepath + right_fold + img for img in train]\n    disp_train = [filepath + disp_noc + img for img in train]\n\n    left_val = [filepath + left_fold + img for img in val]\n    right_val = [filepath + right_fold + img for img in val]\n    disp_val = [filepath + disp_noc + img for img in val]\n\n    return left_train, right_train, disp_train, left_val, right_val, disp_val\n\n\ndef dataloader_KITTI_test(filepath):\n    left_fold = 'colored_0/'\n    right_fold = 'colored_1/'\n    disp_noc = 'disp_occ/'\n\n    image = [img for img in os.listdir(filepath + left_fold) if img.find('_10') > -1]\n\n    train = image[:]\n    val = image[:]\n\n    left_train = [filepath + left_fold + img for img in train]\n    right_train = [filepath + right_fold + img for img in train]\n    disp_train = [filepath + disp_noc + img for img in train]\n\n    left_val = [filepath + left_fold + img for img in val]\n    right_val = [filepath + right_fold + img for img in val]\n    disp_val = [filepath + disp_noc + img for img in val]\n\n    return left_train, right_train, disp_train, left_val, right_val, disp_val\n\n\ndef dataloader_KITTI2015(filepath):\n    left_fold = 'image_2/'\n    right_fold = 'image_3/'\n    disp_L = 'disp_occ_0/'\n    disp_R = 'disp_occ_1/'\n\n    image = [img for img in os.listdir(filepath + left_fold) if img.find('_10') > -1]\n\n    train = image[:]\n    val = image[:]\n\n    left_train = [filepath + left_fold + img for img in train]\n    right_train = [filepath + right_fold + img for img in train]\n    disp_train_L = [filepath + disp_L + img for img in train]\n    disp_train_R = [filepath + disp_R + img for img in train]\n\n    left_val = [filepath + left_fold + img for img in val]\n    right_val = [filepath + right_fold + img for img in val]\n    disp_val_L = [filepath + disp_L + img for img in val]\n    disp_val_R = [filepath + disp_R + img for img in val]\n\n    return left_train, right_train, disp_train_L, left_val, right_val, disp_val_L\n    # return left_train, right_train, disp_train_L\n\n\ndef dataloader_KITTI2015_test(filepath):\n    left_fold = 'image_2/'\n    right_fold = 'image_3/'\n    disp_L = 'disp_occ_0/'\n    disp_R = 'disp_occ_1/'\n\n    image = [img for img in os.listdir(filepath + left_fold) if img.find('_10') > -1]\n\n    train = image[:]\n    val = image[:]\n\n    left_train = [filepath + left_fold + img for img in train]\n    right_train = [filepath + right_fold + img for img in train]\n    disp_train_L = [filepath + disp_L + img for img in train]\n    disp_train_R = [filepath + disp_R + img for img in train]\n\n    left_val = [filepath + left_fold + img for img in val]\n    right_val = [filepath + right_fold + img for img in val]\n    disp_val_L = [filepath + disp_L + img for img in val]\n    disp_val_R = [filepath + disp_R + img for img in val]\n\n    return left_train, right_train, disp_train_L, left_val, right_val, disp_val_L\n    # return left_train, right_train, disp_train_L\n\n\ndef dataloader_SceneFlow(filepath):\n    classes = [d for d in os.listdir(filepath) if os.path.isdir(os.path.join(filepath, d))]\n    image = [img for img in classes if img.find('frames_finalpass') > -1]\n    disp = [dsp for dsp in classes if dsp.find('disparity') > -1]\n\n    monkaa_path = filepath + [x for x in image if 'monkaa' in x][0]\n    monkaa_disp = filepath + [x for x in disp if 'monkaa' in x][0]\n\n    monkaa_dir = os.listdir(monkaa_path)\n\n    all_left_img = []\n    all_right_img = []\n    all_left_disp = []\n    test_left_img = []\n    test_right_img = []\n    test_left_disp = []\n\n    for dd in monkaa_dir:\n        for im in os.listdir(monkaa_path + '/' + dd + '/left/'):\n            if is_image_file(monkaa_path + '/' + dd + '/left/' + im):\n                all_left_img.append(monkaa_path + '/' + dd + '/left/' + im)\n                all_left_disp.append(monkaa_disp + '/' + dd + '/left/' + im.split(\".\")[0] + '.pfm')\n\n        for im in os.listdir(monkaa_path + '/' + dd + '/right/'):\n            if is_image_file(monkaa_path + '/' + dd + '/right/' + im):\n                all_right_img.append(monkaa_path + '/' + dd + '/right/' + im)\n\n    flying_path = filepath + [x for x in image if x == 'frames_finalpass'][0]\n    flying_disp = filepath + [x for x in disp if x == 'frames_disparity'][0]\n    flying_dir = flying_path + '/TRAIN/'\n    subdir = ['A', 'B', 'C']\n\n    for ss in subdir:\n        flying = os.listdir(flying_dir + ss)\n\n        for ff in flying:\n            imm_l = os.listdir(flying_dir + ss + '/' + ff + '/left/')\n            for im in imm_l:\n                if is_image_file(flying_dir + ss + '/' + ff + '/left/' + im):\n                    all_left_img.append(flying_dir + ss + '/' + ff + '/left/' + im)\n\n                all_left_disp.append(flying_disp + '/TRAIN/' + ss + '/' + ff + '/left/' + im.split(\".\")[0] + '.pfm')\n\n                if is_image_file(flying_dir + ss + '/' + ff + '/right/' + im):\n                    all_right_img.append(flying_dir + ss + '/' + ff + '/right/' + im)\n\n    flying_dir = flying_path + '/TEST/'\n\n    subdir = ['A', 'B', 'C']\n\n    for ss in subdir:\n        flying = os.listdir(flying_dir + ss)\n\n        for ff in flying:\n            imm_l = os.listdir(flying_dir + ss + '/' + ff + '/left/')\n            for im in imm_l:\n                if is_image_file(flying_dir + ss + '/' + ff + '/left/' + im):\n                    test_left_img.append(flying_dir + ss + '/' + ff + '/left/' + im)\n\n                test_left_disp.append(flying_disp + '/TEST/' + ss + '/' + ff + '/left/' + im.split(\".\")[0] + '.pfm')\n\n                if is_image_file(flying_dir + ss + '/' + ff + '/right/' + im):\n                    test_right_img.append(flying_dir + ss + '/' + ff + '/right/' + im)\n\n    driving_dir = filepath + [x for x in image if 'driving' in x][0] + '/'\n    driving_disp = filepath + [x for x in disp if 'driving' in x][0]\n\n    subdir1 = ['35mm_focallength', '15mm_focallength']\n    subdir2 = ['scene_backwards', 'scene_forwards']\n    subdir3 = ['fast', 'slow']\n\n    for i in subdir1:\n        for j in subdir2:\n            for k in subdir3:\n                imm_l = os.listdir(driving_dir + i + '/' + j + '/' + k + '/left/')\n                for im in imm_l:\n                    if is_image_file(driving_dir + i + '/' + j + '/' + k + '/left/' + im):\n                        all_left_img.append(driving_dir + i + '/' + j + '/' + k + '/left/' + im)\n                    all_left_disp.append(\n                        driving_disp + '/' + i + '/' + j + '/' + k + '/left/' + im.split(\".\")[0] + '.pfm')\n\n                    if is_image_file(driving_dir + i + '/' + j + '/' + k + '/right/' + im):\n                        all_right_img.append(driving_dir + i + '/' + j + '/' + k + '/right/' + im)\n\n    return all_left_img, all_right_img, all_left_disp, test_left_img, test_right_img, test_left_disp\n\n\nclass myImageFloder_SceneFlow(data.Dataset):\n    def __init__(self, left, right, left_disparity, training, loader=default_loader,\n                 dploader=disparity_loader_SceneFlow):\n\n        self.left = left\n        self.right = right\n        self.disp_L = left_disparity\n        self.loader = loader\n        self.dploader = dploader\n        self.training = training\n\n    def __getitem__(self, index):\n        left = self.left[index]\n        right = self.right[index]\n        disp_L = self.disp_L[index]\n\n        left_img = self.loader(left)\n        right_img = self.loader(right)\n        dataL, scaleL = self.dploader(disp_L)\n        dataL = np.ascontiguousarray(dataL, dtype=np.float32)\n\n        if self.training:\n            w, h = left_img.size\n            th, tw = 256, 512\n\n            x1 = random.randint(0, w - tw)\n            y1 = random.randint(0, h - th)\n\n            left_img = left_img.crop((x1, y1, x1 + tw, y1 + th))\n            right_img = right_img.crop((x1, y1, x1 + tw, y1 + th))\n\n            dataL = dataL[y1:y1 + th, x1:x1 + tw]\n\n            processed = get_transform(augment=False)\n            left_img = processed(left_img)\n            right_img = processed(right_img)\n\n            return left_img, right_img, dataL\n\n        else:\n            processed = get_transform(augment=False)\n            left_img = processed(left_img)\n            right_img = processed(right_img)\n\n            return left_img, right_img, dataL\n\n    def __len__(self):\n        return len(self.left)\n\nclass myImageFloder_KITTI(data.Dataset):\n    def __init__(self, left, right, left_disparity, training, loader=default_loader, dploader=disparity_loader_KITTI):\n\n        self.left = left\n        self.right = right\n        self.disp_L = left_disparity\n        # self.disp_R = right_disparity\n        self.loader = loader\n        self.dploader = dploader\n        self.training = training\n\n    def __getitem__(self, index):\n        left = self.left[index]\n        right = self.right[index]\n        left_img = self.loader(left)\n        right_img = self.loader(right)\n\n        disp_L = self.disp_L[index]\n        dataL = self.dploader(disp_L)\n        if self.training:\n            w, h = left_img.size\n            th, tw = 256, 512\n\n            random_brightness = np.random.uniform(0.5, 2.0, 2)\n            random_gamma = np.random.uniform(0.8, 1.2, 2)\n            random_contrast = np.random.uniform(0.8, 1.2, 2)\n            left_img = torchvision.transforms.functional.adjust_brightness(left_img, random_brightness[0])\n            left_img = torchvision.transforms.functional.adjust_gamma(left_img, random_gamma[0])\n            left_img = torchvision.transforms.functional.adjust_contrast(left_img, random_contrast[0])\n            right_img = torchvision.transforms.functional.adjust_brightness(right_img, random_brightness[1])\n            right_img = torchvision.transforms.functional.adjust_gamma(right_img, random_gamma[1])\n            right_img = torchvision.transforms.functional.adjust_contrast(right_img, random_contrast[1])\n\n            x1 = random.randint(0, w - tw)\n            y1 = random.randint(0, h - th)\n\n            left_img = left_img.crop((x1, y1, x1 + tw, y1 + th))\n            right_img = right_img.crop((x1, y1, x1 + tw, y1 + th))\n            right_img = np.array(right_img)\n            left_img = np.array(left_img)\n\n            right_img.flags.writeable = True\n            if np.random.binomial(1, 0.2):\n                sx = int(np.random.uniform(35, 100))\n                sy = int(np.random.uniform(25, 75))\n                cx = int(np.random.uniform(sx, right_img.shape[0] - sx))\n                cy = int(np.random.uniform(sy, right_img.shape[1] - sy))\n                right_img[cx - sx:cx + sx, cy - sy:cy + sy] = np.mean(np.mean(right_img, 0), 0)[np.newaxis, np.newaxis]\n\n            dataL = np.ascontiguousarray(dataL, dtype=np.float32) / 256\n            dataL = dataL[y1:y1 + th, x1:x1 + tw]\n            # dataR = np.ascontiguousarray(dataR, dtype=np.float32) / 256\n            # dataR = dataR[y1:y1 + th, x1:x1 + tw]\n\n            processed = get_transform(augment=False)\n            left_img = processed(left_img)\n            right_img = processed(right_img)\n\n            return left_img, right_img, dataL\n\n        else:\n            w, h = left_img.size\n            left_img = left_img.crop((w - 1232, h - 368, w, h))\n            right_img = right_img.crop((w - 1232, h - 368, w, h))\n\n            dataL = dataL.crop((w - 1232, h - 368, w, h))\n            dataL = np.ascontiguousarray(dataL, dtype=np.float32) / 256\n            # dataR = dataR.crop((w - 1232, h - 368, w, h))\n            # dataR = np.ascontiguousarray(dataR, dtype=np.float32) / 256\n\n            processed = get_transform(augment=False)\n            left_img = processed(left_img)\n            right_img = processed(right_img)\n\n            return left_img, right_img, dataL\n\n    def __len__(self):\n        return len(self.left)\n\n\nclass myImageFloder_eth3d(data.Dataset):\n\n    def __init__(self, left, right, left_disparity, training, loader=default_loader, dploader=cv2_disparity_loader):\n        self.left = left\n        self.right = right\n        self.disp_L = left_disparity\n\n        self.training = training\n        self.loader = loader\n        self.dploader = dploader\n\n    def __getitem__(self, index):\n        left = self.left[index]\n        right = self.right[index]\n        left_img = self.loader(left)\n        right_img = self.loader(right)\n\n        disp_L = self.disp_L[index]\n        flag = False\n        if '.png' in disp_L:\n            dataL = self.dploader(disp_L)\n            flag = True\n        else:\n            dataL, scaleL = self.dploader(disp_L)\n\n\n        if self.training:\n            w, h = left_img.size\n            th, tw = 256, 512\n            #th, tw = 320, 704\n\n            random_brightness = np.random.uniform(0.5, 2.0, 2)\n            random_gamma = np.random.uniform(0.8, 1.2, 2)\n            random_contrast = np.random.uniform(0.8, 1.2, 2)\n            left_img = torchvision.transforms.functional.adjust_brightness(left_img, random_brightness[0])\n            left_img = torchvision.transforms.functional.adjust_gamma(left_img, random_gamma[0])\n            left_img = torchvision.transforms.functional.adjust_contrast(left_img, random_contrast[0])\n            right_img = torchvision.transforms.functional.adjust_brightness(right_img, random_brightness[1])\n            right_img = torchvision.transforms.functional.adjust_gamma(right_img, random_gamma[1])\n            right_img = torchvision.transforms.functional.adjust_contrast(right_img, random_contrast[1])\n\n            x1 = random.randint(0, w - tw)\n            y1 = random.randint(0, h - th)\n\n            left_img = left_img.crop((x1, y1, x1 + tw, y1 + th))\n            right_img = right_img.crop((x1, y1, x1 + tw, y1 + th))\n            right_img = np.array(right_img)\n            left_img = np.array(left_img)\n\n            right_img.flags.writeable = True\n            if np.random.binomial(1, 0.2):\n              sx = int(np.random.uniform(35, 100))\n              sy = int(np.random.uniform(25, 75))\n              cx = int(np.random.uniform(sx, right_img.shape[0]-sx))\n              cy = int(np.random.uniform(sy, right_img.shape[1]-sy))\n              right_img[cx-sx:cx+sx, cy-sy:cy+sy] = np.mean(np.mean(right_img, 0), 0)[np.newaxis,np.newaxis]\n\n            if flag == True:\n                dataL = np.ascontiguousarray(dataL, dtype=np.float32) / 256\n            else:\n                dataL = np.ascontiguousarray(dataL, dtype=np.float32)\n            dataL = dataL[y1:y1 + th, x1:x1 + tw]\n\n            processed = get_transform(augment=False)\n            left_img = processed(left_img)\n            right_img = processed(right_img)\n\n            return left_img, right_img, dataL\n\n        else:\n            w, h = left_img.size\n            # normalize\n            processed = get_transform(augment=False)\n            left_img = processed(left_img).numpy()\n            right_img = processed(right_img).numpy()\n\n            top_pad = 768 - h\n            right_pad = 1024 - w\n            assert top_pad >= 0 and right_pad >= 0\n\n            # pad images\n            left_img = np.lib.pad(left_img, ((0, 0), (top_pad, 0), (0, right_pad)), mode='constant', constant_values=0)\n            right_img = np.lib.pad(right_img, ((0, 0), (top_pad, 0), (0, right_pad)), mode='constant',\n                               constant_values=0)\n            # pad disparity gt\n            assert len(dataL.shape) == 2\n            dataL = np.lib.pad(dataL, ((top_pad, 0), (0, right_pad)), mode='constant', constant_values=0)\n\n            # print(\"top_pad\",top_pad)\n            # print(\"right_pad\",right_pad)\n            return left_img, right_img, dataL\n\n    def __len__(self):\n        return len(self.left)\n\n\nclass myImageFloder_middlebury(data.Dataset):\n\n    def __init__(self, left, right, left_disparity, training, loader=default_loader, dploader=disparity_loader):\n        self.left = left\n        self.right = right\n        self.disp_L = left_disparity\n        self.training = training\n        self.loader = loader\n        self.dploader = dploader\n\n    def __getitem__(self, index):\n        left = self.left[index]\n        right = self.right[index]\n        left_img = self.loader(left)\n        right_img = self.loader(right)\n\n        disp_L = self.disp_L[index]\n        flag = False\n        if '.png' in disp_L:\n            dataL = self.dploader(disp_L)\n            flag = True\n        else:\n            dataL, scaleL = self.dploader(disp_L)\n\n        dataL[dataL==np.inf] = 0\n\n        if self.training:\n            w, h = left_img.size\n            th, tw = 320, 704\n\n            random_brightness = np.random.uniform(0.5, 2.0, 2)\n            random_gamma = np.random.uniform(0.8, 1.2, 2)\n            random_contrast = np.random.uniform(0.8, 1.2, 2)\n            left_img = torchvision.transforms.functional.adjust_brightness(left_img, random_brightness[0])\n            left_img = torchvision.transforms.functional.adjust_gamma(left_img, random_gamma[0])\n            left_img = torchvision.transforms.functional.adjust_contrast(left_img, random_contrast[0])\n            right_img = torchvision.transforms.functional.adjust_brightness(right_img, random_brightness[1])\n            right_img = torchvision.transforms.functional.adjust_gamma(right_img, random_gamma[1])\n            right_img = torchvision.transforms.functional.adjust_contrast(right_img, random_contrast[1])\n\n            x1 = random.randint(0, w - tw)\n            y1 = random.randint(0, h - th)\n\n            left_img = left_img.crop((x1, y1, x1 + tw, y1 + th))\n            right_img = right_img.crop((x1, y1, x1 + tw, y1 + th))\n            right_img = np.array(right_img)\n            left_img = np.array(left_img)\n\n            right_img.flags.writeable = True\n            if np.random.binomial(1, 0.2):\n              sx = int(np.random.uniform(35, 100))\n              sy = int(np.random.uniform(25, 75))\n              cx = int(np.random.uniform(sx, right_img.shape[0]-sx))\n              cy = int(np.random.uniform(sy, right_img.shape[1]-sy))\n              right_img[cx-sx:cx+sx, cy-sy:cy+sy] = np.mean(np.mean(right_img, 0), 0)[np.newaxis,np.newaxis]\n\n            if flag == True:\n                dataL = np.ascontiguousarray(dataL, dtype=np.float32) / 256\n            else:\n                dataL = np.ascontiguousarray(dataL, dtype=np.float32)\n\n            dataL = dataL[y1:y1 + th, x1:x1 + tw]\n\n            processed = get_transform(augment=False)\n            left_img = processed(left_img)\n            right_img = processed(right_img)\n\n            return left_img, right_img, dataL\n\n        # else:\n        #     w, h = left_img.size\n        #     # normalize\n        #     processed = get_transform(augment=False)\n        #     left_img = processed(left_img).numpy()\n        #     right_img = processed(right_img).numpy()\n        #\n        #     dataL = dataL.crop((w - 1536, h - 1024, w, h))\n        #     dataL = np.ascontiguousarray(dataL, dtype=np.float32) / 256\n        #\n        #     top_pad = 1024 - h\n        #     right_pad = 1536 - w\n        #     assert top_pad >= 0 and right_pad >= 0\n        #\n        #     # pad images\n        #     left_img = np.lib.pad(left_img, ((0, 0), (top_pad, 0), (0, right_pad)), mode='constant', constant_values=0)\n        #     right_img = np.lib.pad(right_img, ((0, 0), (top_pad, 0), (0, right_pad)), mode='constant',\n        #                        constant_values=0)\n        #     # pad disparity gt\n        #     assert len(dataL.shape) == 2\n        #     dataL = np.lib.pad(dataL, ((top_pad, 0), (0, right_pad)), mode='constant', constant_values=0)\n        #\n        #     # print(\"top_pad\",top_pad)\n        #     # print(\"right_pad\",right_pad)\n        #     return left_img, right_img, dataL\n\n        else:\n            dataL = np.ascontiguousarray(dataL, dtype=np.float32)\n\n            processed = get_transform(augment=False)\n            left_img = processed(left_img).unsqueeze(0)\n            right_img = processed(right_img).unsqueeze(0)\n\n            padder = InputPadder(left_img.shape, divis_by=16)\n            images, pads = padder.pad(left_img, right_img)\n\n            return images[0].squeeze(), images[1].squeeze(), dataL, pads\n\n    def __len__(self):\n        return len(self.left)\n\n\n\nclass myImageFloder_middlebury_additional(data.Dataset):\n\n    def __init__(self, left, right, left_disparity, training, loader=default_loader, dploader=disparity_loader):\n        self.left = left\n        self.right = right\n        self.disp_L = left_disparity\n\n        self.training = training\n        self.loader = loader\n        self.dploader = dploader\n\n    def __getitem__(self, index):\n        left = self.left[index]\n        right = self.right[index]\n\n        left_img = cv2.imread(left, cv2.IMREAD_COLOR)\n        right_img = cv2.imread(right, cv2.IMREAD_COLOR)\n\n        resize_scale = 0.5\n        left_img = cv2.resize(\n            left_img,\n            None,\n            fx=resize_scale,\n            fy=resize_scale,\n            interpolation=cv2.INTER_AREA,\n        )\n        right_img = cv2.resize(\n            right_img,\n            None,\n            fx=resize_scale,\n            fy=resize_scale,\n            interpolation=cv2.INTER_AREA,\n        )\n\n        left_img = Image.fromarray(left_img.astype('uint8')).convert('RGB')\n        right_img = Image.fromarray(right_img.astype('uint8')).convert('RGB')\n\n        disp_L = self.disp_L[index]\n        flag = False\n\n        if '.png' in disp_L:\n            dataL = self.dploader(disp_L)\n            flag = True\n        else:\n            dataL, scaleL = self.dploader(disp_L)\n\n        dataL = (\n            cv2.resize(\n            dataL,\n            None,\n            fx=resize_scale,\n            fy=resize_scale,\n            interpolation=cv2.INTER_AREA,\n            )\n            * resize_scale\n        )\n\n        dataL[dataL==np.inf] = 0\n\n        if self.training:\n            w, h = left_img.size\n            th, tw = 256, 512\n            #th, tw = 320, 704\n\n            random_brightness = np.random.uniform(0.5, 2.0, 2)\n            random_gamma = np.random.uniform(0.8, 1.2, 2)\n            random_contrast = np.random.uniform(0.8, 1.2, 2)\n            left_img = torchvision.transforms.functional.adjust_brightness(left_img, random_brightness[0])\n            left_img = torchvision.transforms.functional.adjust_gamma(left_img, random_gamma[0])\n            left_img = torchvision.transforms.functional.adjust_contrast(left_img, random_contrast[0])\n            right_img = torchvision.transforms.functional.adjust_brightness(right_img, random_brightness[1])\n            right_img = torchvision.transforms.functional.adjust_gamma(right_img, random_gamma[1])\n            right_img = torchvision.transforms.functional.adjust_contrast(right_img, random_contrast[1])\n\n            x1 = random.randint(0, w - tw)\n            y1 = random.randint(0, h - th)\n\n            left_img = left_img.crop((x1, y1, x1 + tw, y1 + th))\n            right_img = right_img.crop((x1, y1, x1 + tw, y1 + th))\n            right_img = np.array(right_img)\n            left_img = np.array(left_img)\n\n            right_img.flags.writeable = True\n            if np.random.binomial(1, 0.2):\n              sx = int(np.random.uniform(35, 100))\n              sy = int(np.random.uniform(25, 75))\n              cx = int(np.random.uniform(sx, right_img.shape[0]-sx))\n              cy = int(np.random.uniform(sy, right_img.shape[1]-sy))\n              right_img[cx-sx:cx+sx, cy-sy:cy+sy] = np.mean(np.mean(right_img, 0), 0)[np.newaxis,np.newaxis]\n\n            if flag == True:\n                dataL = np.ascontiguousarray(dataL, dtype=np.float32) / 256\n            else:\n                dataL = np.ascontiguousarray(dataL, dtype=np.float32)\n\n            dataL = dataL[y1:y1 + th, x1:x1 + tw]\n\n            processed = get_transform(augment=False)\n            left_img = processed(left_img)\n            right_img = processed(right_img)\n\n            return left_img, right_img, dataL\n\n        else:\n            dataL = np.ascontiguousarray(dataL, dtype=np.float32)\n            w, h = left_img.size\n\n            # normalize\n            processed = get_transform(augment=False)\n            left_img = processed(left_img).numpy()\n            right_img = processed(right_img).numpy()\n\n            top_pad = 1024 - h\n            right_pad = 1536 - w\n            assert top_pad >= 0 and right_pad >= 0\n\n            # pad images\n            left_img = np.lib.pad(left_img, ((0, 0), (top_pad, 0), (0, right_pad)), mode='constant', constant_values=0)\n            right_img = np.lib.pad(right_img, ((0, 0), (top_pad, 0), (0, right_pad)), mode='constant',\n                               constant_values=0)\n            # pad disparity gt\n            assert len(dataL.shape) == 2\n            dataL = np.lib.pad(dataL, ((top_pad, 0), (0, right_pad)), mode='constant', constant_values=0)\n\n            # print(\"top_pad\",top_pad)\n            # print(\"right_pad\",right_pad)\n            return left_img, right_img, dataL\n\n#         else:\n#             dataL = np.ascontiguousarray(dataL, dtype=np.float32)\n#\n#             processed = get_transform(augment=False)\n#             left_img = processed(left_img).unsqueeze(0)\n#             right_img = processed(right_img).unsqueeze(0)\n#\n#             padder = InputPadder(left_img.shape, divis_by=16)\n#             images, pads = padder.pad(left_img, right_img)\n#\n#             return images[0].squeeze(), images[1].squeeze(), dataL, pads\n#\n    def __len__(self):\n        return len(self.left)\n\n\n\n\nclass InputPadder:\n    \"\"\" Pads images such that dimensions are divisible by 8 \"\"\"\n    def __init__(self, dims, mode='sintel', divis_by=8):\n        self.ht, self.wd = dims[-2:]\n        pad_ht = (((self.ht // divis_by) + 1) * divis_by - self.ht) % divis_by\n        pad_wd = (((self.wd // divis_by) + 1) * divis_by - self.wd) % divis_by\n        if mode == 'sintel':\n            self._pad = [pad_wd//2, pad_wd - pad_wd//2, pad_ht//2, pad_ht - pad_ht//2]\n        else:\n            self._pad = [pad_wd//2, pad_wd - pad_wd//2, 0, pad_ht]\n\n    def pad(self, *inputs):\n        assert all((x.ndim == 4) for x in inputs)\n        return [F.pad(x, self._pad, mode='replicate') for x in inputs], self._pad\n        # return [F.pad(x, self._pad, mode='constant', value=0) for x in inputs], self._pad\n\n"
        }
    ]
}